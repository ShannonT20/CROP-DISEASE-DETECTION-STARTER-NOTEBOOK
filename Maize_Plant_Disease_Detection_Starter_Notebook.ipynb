{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maize Plant Disease Detection Starter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI for Crop Health - Diagnosing Maize Plant Diseases in Zimbabwe Using Deep Learning\n",
    "\n",
    "## üìå Info Page\n",
    "\n",
    "### About the Challenge\n",
    "Maize is the staple crop that sustains millions of Zimbabweans, underpinning both food security and livelihoods across rural and urban communities. Yet, Zimbabwe‚Äôs maize production is persistently threatened by several devastating leaf diseases‚Äîprimarily **Common Rust**, **Gray Leaf Spot**, and **Blight**‚Äîwhich cause significant yield reductions and economic losses.\n",
    "\n",
    "These diseases are widespread across Zimbabwe‚Äôs diverse agro-ecological zones, including:\n",
    "- High-rainfall areas like **Mashonaland East** and **Manicaland**.\n",
    "- Drier regions like **Masvingo**.\n",
    "- The central **Midlands**.\n",
    "\n",
    "Their impact is exacerbated by limited access to timely and accurate disease diagnostics, especially for smallholder farmers who form the backbone of Zimbabwe‚Äôs agriculture.\n",
    "\n",
    "### Your Task\n",
    "Develop **deep learning models** that can accurately detect and classify maize diseases from leaf images. Leveraging AI for early and precise disease identification can transform farming practices by:\n",
    "- Providing farmers with **real-time, accessible tools** to identify diseases before they spread widely.\n",
    "- Reducing reliance on **manual inspection**, which is often subjective and slow.\n",
    "- Enabling **targeted interventions** to minimize crop loss and reduce pesticide overuse.\n",
    "- Contributing to **improved food security** and agricultural sustainability in Zimbabwe.\n",
    "\n",
    "### Dataset Overview\n",
    "The dataset includes images of maize leaves categorized into:\n",
    "1. **Common Rust**\n",
    "2. **Gray Leaf Spot**\n",
    "3. **Blight**\n",
    "4. **Healthy**\n",
    "\n",
    "Your challenge is to design and train models robust to diverse field conditions (e.g., varying lighting, leaf angles, and disease severity).\n",
    "\n",
    "### Impact\n",
    "By addressing this challenge, you will contribute to a **high-impact solution** with direct applications in Zimbabwe‚Äôs farming communities and beyond, driving the adoption of AI-powered precision agriculture in sub-Saharan Africa.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Evaluation\n",
    "- **Metrics**: Accuracy, Precision, Recall, F1-Score.\n",
    "- **Leaderboard**: Based on performance on the evaluation set.\n",
    "# \n",
    "### üèÜ Prizes\n",
    " - **Top 3 performers** will receive:\n",
    "   - Official certification of achievement\n",
    "   - Recognition on our community platforms\n",
    "   - Priority consideration for future opportunities with:\n",
    "     - The Deep Learning Indaba X Zimbabwe community\n",
    "     - Agricultural sector partners\n",
    "\n",
    "## ‚è≥ Timeline\n",
    "- **Start Date**: [Insert Date]\n",
    "- **Submission Deadline**: [Insert Date]\n",
    "- **Results Announcement**: [Insert Date]\n",
    "\n",
    "## üìú Rules\n",
    "- This challenge is **only open to the Deep Learning Indaba X Zimbabwe Community**.\n",
    "- Teams must adhere to the **code of conduct** and **submission guidelines**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìÇ Data Page\n",
    "\n",
    "### About the Data\n",
    "The dataset contains labelled images of crop leaves, categorized into four classes:\n",
    "\n",
    "| Class          | Label | Number of Images |\n",
    "|----------------|-------|------------------|\n",
    "| Common Rust    | 0     | 1,306            |\n",
    "| Gray Leaf Spot | 1     | 574              |\n",
    "| Blight         | 2     | 1,146            |\n",
    "| Healthy        | 3     | 1,162            |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå± Starter Notebook:  Maize Plant Disease Detection \n",
    "\n",
    "## üìå Overview\n",
    "This notebook serves as a **starter template** for the *AI for Crop Health* hackathon challenge. It provides a foundational workflow for loading, preprocessing, and analyzing the maize disease dataset, as well as training a baseline deep learning model. Use this as a jumping-off point to build and refine your solution.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objectives\n",
    "By the end of this notebook, you will:\n",
    "1. **Explore the dataset**: Visualize sample images and understand class distributions.\n",
    "2. **Preprocess data**: Resize, normalize, and augment images for model training.\n",
    "3. **Train a baseline model**: Implement a simple CNN or transfer learning model.\n",
    "4. **Evaluate performance**: Calculate metrics (accuracy, F1-score) and identify areas for improvement.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchinfo\n",
    "import torchvision\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring and Preparing Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Directory: crop pictures\\data\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(\"crop pictures\", \"data\")\n",
    "\n",
    "print(\"Data Directory:\", data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of classes: ['Blight', 'Common_Rust', 'Gray_Leaf_Spot', 'Healthy']\n"
     ]
    }
   ],
   "source": [
    "#Create and print a list of class names in our directory\n",
    "classes = os.listdir(data_dir)\n",
    "\n",
    "print(\"List of classes:\", classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert grayscale images to RGB format since our model expects 3-channel input\n",
    "# Grayscale images only have 1 channel, which would cause dimension mismatch errors\n",
    "# This ensures all images have consistent 3-channel RGB format for model training\n",
    "def convert_to_rgb(img):\n",
    "    \"\"\"Convert PIL image to RGB format if it isn't already.\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image object\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image object in RGB format\n",
    "    \"\"\"\n",
    "    if img.mode != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(loader):\n",
    "    \"\"\"Computes the mean and standard deviation of image data.\n",
    "\n",
    "    Input: a `DataLoader` producing tensors of shape [batch_size, channels, pixels_x, pixels_y]\n",
    "    Output: the mean of each channel as a tensor, the standard deviation of each channel as a tensor\n",
    "            formatted as a tuple (means[channels], std[channels])\"\"\"\n",
    "\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in tqdm(loader, desc=\"Computing mean and std\", leave=False):\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "    mean = channels_sum / num_batches\n",
    "    std = (channels_squared_sum / num_batches - mean**2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.transforms.transforms.Compose'>\n",
      "-----------------\n",
      "Compose(\n",
      "    Lambda()\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=tensor([0.4379, 0.4983, 0.3759]), std=tensor([0.2096, 0.2157, 0.2093]))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Resize images to 224x224 to ensure consistent input dimensions for the model (common size for CNNs)\n",
    "# Convert images to tensors to enable GPU acceleration and matrix operations\n",
    "# Normalize each color channel separately (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "# to standardize pixel values across the dataset (values based on ImageNet statistics)\n",
    "# First create a basic transform to get images to tensor format for mean/std calculation\n",
    "temp_transform = transforms.Compose([\n",
    "    transforms.Lambda(convert_to_rgb),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create temporary dataset and loader for mean/std calculation\n",
    "temp_dataset = datasets.ImageFolder(data_dir, transform=temp_transform)\n",
    "temp_loader = DataLoader(temp_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Calculate dataset statistics\n",
    "mean, std = get_mean_std(temp_loader)\n",
    "\n",
    "# Final transform with calculated normalization values\n",
    "transform_normalized = transforms.Compose([\n",
    "    transforms.Lambda(convert_to_rgb),  # First convert to RGB if needed\n",
    "    transforms.Resize((224, 224)),      # Resize to 224x224\n",
    "    transforms.ToTensor(),              # Convert to tensor\n",
    "    transforms.Normalize(               # Normalize with calculated stats\n",
    "        mean=mean,\n",
    "        std=std\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "print(type(transform_normalized))\n",
    "print(\"-----------------\")\n",
    "print(transform_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 4188\n"
     ]
    }
   ],
   "source": [
    "#We make a normalizes dataset using ImageFolder from datasets and print lenght\n",
    "dataset = datasets.ImageFolder(data_dir,transform_normalized)\n",
    "print('Length of dataset:', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
