{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset split into train, val, and test sets.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Define source and destination directories\n",
    "SOURCE_DIR = 'crop pictures/data'\n",
    "DEST_DIR = 'crop pictures'\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Ensure total = 1.0\n",
    "assert abs((train_ratio + val_ratio + test_ratio) - 1.0) < 1e-6, \"Ratios must sum to 1.0\"\n",
    "\n",
    "# Get class names (folder names)\n",
    "classes = [d for d in os.listdir(SOURCE_DIR) if os.path.isdir(os.path.join(SOURCE_DIR, d))]\n",
    "\n",
    "# Create output directory structure\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for class_name in classes:\n",
    "        Path(os.path.join(DEST_DIR, split, class_name)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process each class\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(SOURCE_DIR, class_name)\n",
    "    images = os.listdir(class_path)\n",
    "    images = [img for img in images if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    random.shuffle(images)\n",
    "\n",
    "    total = len(images)\n",
    "    train_end = int(total * train_ratio)\n",
    "    val_end = train_end + int(total * val_ratio)\n",
    "\n",
    "    train_imgs = images[:train_end]\n",
    "    val_imgs = images[train_end:val_end]\n",
    "    test_imgs = images[val_end:]\n",
    "\n",
    "    # Copy files\n",
    "    for img_name in train_imgs:\n",
    "        shutil.copy(os.path.join(class_path, img_name), os.path.join(DEST_DIR, 'train', class_name, img_name))\n",
    "    for img_name in val_imgs:\n",
    "        shutil.copy(os.path.join(class_path, img_name), os.path.join(DEST_DIR, 'val', class_name, img_name))\n",
    "    for img_name in test_imgs:\n",
    "        shutil.copy(os.path.join(class_path, img_name), os.path.join(DEST_DIR, 'test', class_name, img_name))\n",
    "\n",
    "print(\"✅ Dataset split into train, val, and test sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ No duplicate images between train and val sets\n",
      "✅ No duplicate images between train and test sets\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate images across splits\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Define source and destination directories\n",
    "SOURCE_DIR = 'crop pictures/data'\n",
    "DEST_DIR = 'crop pictures'\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Ensure total = 1.0\n",
    "assert abs((train_ratio + val_ratio + test_ratio) - 1.0) < 1e-6, \"Ratios must sum to 1.0\"\n",
    "\n",
    "# Get class names (folder names)\n",
    "classes = [d for d in os.listdir(SOURCE_DIR) if os.path.isdir(os.path.join(SOURCE_DIR, d))]\n",
    "\n",
    "\n",
    "def check_duplicates_across_splits():\n",
    "    splits = ['train', 'val_pre_updated', 'test']\n",
    "    image_sets = {split: set() for split in splits}\n",
    "    \n",
    "    for split in splits:\n",
    "        for class_name in classes:\n",
    "            split_path = os.path.join(DEST_DIR, split, class_name)\n",
    "            if os.path.exists(split_path):\n",
    "                images = os.listdir(split_path)\n",
    "                image_sets[split].update(images)\n",
    "    \n",
    "    # Check for duplicates between train and val/test\n",
    "    train_val_duplicates = image_sets['train'] & image_sets['val_pre_updated']\n",
    "    train_test_duplicates = image_sets['train'] & image_sets['test']\n",
    "    \n",
    "    if train_val_duplicates:\n",
    "        print(f\"⚠️ Found {len(train_val_duplicates)} duplicate images between train and val sets\")\n",
    "    else:\n",
    "        print(\"✅ No duplicate images between train and val sets\")\n",
    "    \n",
    "    if train_test_duplicates:\n",
    "        print(f\"⚠️ Found {len(train_test_duplicates)} duplicate images between train and test sets\")\n",
    "    else:\n",
    "        print(\"✅ No duplicate images between train and test sets\")\n",
    "\n",
    "check_duplicates_across_splits()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample submission file 'sample_submission.csv' created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample submission DataFrame with example data\n",
    "sample_submission = pd.DataFrame({\n",
    "    'ID': ['image_000001.jpg', 'image_000002.JPG', 'image_000003.JPG', \n",
    "           'image_000004.JPG', 'image_000005.JPG'],\n",
    "    'Blight': [0.73140, 0.00108, 0.00000, 0.26471, 0.00045],\n",
    "    'Common_Rust': [0.01391, 0.00085, 1.00000, 0.03529, 0.00035],\n",
    "    'Gray_Leaf_Spot': [0.23257, 0.00012, 0.00000, 0.06836, 0.00012],\n",
    "    'Healthy': [0.02212, 0.99795, 0.00000, 0.63164, 0.99908]\n",
    "})\n",
    "\n",
    "# Save the sample submission file\n",
    "sample_submission.to_csv('sample_submission.csv', index=False)\n",
    "print(\"Sample submission file 'sample_submission.csv' created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load ground truth and predictions\n",
    "ground_truth = pd.read_csv('ground_truth.csv')  # Columns: ID, True_Label\n",
    "    # Your confidence scores output\n",
    "\n",
    "# 2. Merge them on filename\n",
    "combined = pd.merge(confidence_df, ground_truth, on='ID')\n",
    "\n",
    "# 3. Calculate accuracy metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Get predicted labels (class with highest confidence)\n",
    "combined['Predicted'] = combined[['Blight','Common_Rust','Gray_Leaf_Spot','Healthy']].idxmax(axis=1)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = accuracy_score(combined['True_Label'], combined['Predicted'])\n",
    "print(f\"Overall Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Detailed class-wise metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    combined['True_Label'], \n",
    "    combined['Predicted'],\n",
    "    target_names=['Blight','Common_Rust','Gray_Leaf_Spot','Healthy']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Create train.csv\n",
    "train_data = []\n",
    "train_dir = \"crop pictures/train\"\n",
    "for label in [\"Blight\", \"Common_Rust\", \"Gray_Leaf_Spot\", \"Healthy\"]:\n",
    "    label_dir = os.path.join(train_dir, label)\n",
    "    for filename in os.listdir(label_dir):\n",
    "        if filename.endswith(('.jpg', '.JPG')):\n",
    "            train_data.append([filename, label])\n",
    "\n",
    "with open('Train.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['image_id', 'label'])  # header\n",
    "    writer.writerows(train_data)\n",
    "\n",
    "# Create val.csv\n",
    "val_data = []\n",
    "val_dir = \"crop pictures/val\"\n",
    "for label in [\"Blight\", \"Common_Rust\", \"Gray_Leaf_Spot\", \"Healthy\"]:\n",
    "    label_dir = os.path.join(val_dir, label)\n",
    "    for filename in os.listdir(label_dir):\n",
    "        if filename.endswith(('.jpg', '.JPG')):\n",
    "            val_data.append([filename, label])\n",
    "\n",
    "with open('Val.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['image_id', 'label'])  # header\n",
    "    writer.writerows(val_data)\n",
    "\n",
    "# Create test.csv\n",
    "test_dir = \"crop pictures/test\"\n",
    "test_data = []\n",
    "for filename in os.listdir(test_dir):\n",
    "    if filename.endswith(('.jpg', '.JPG')):\n",
    "        test_data.append([filename])\n",
    "\n",
    "with open('Test.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['image_id'])  # header\n",
    "    writer.writerows(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
